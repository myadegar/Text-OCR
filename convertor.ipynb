{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import os\n",
    "import glob\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "from mtranslate import translate\n",
    "from pytesseract import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function\n",
    "def removing_files(folder_name):\n",
    "    \"\"\"\n",
    "    delete files. \n",
    "  \n",
    "    delete all files in a root folder. \n",
    "  \n",
    "    Parameters: \n",
    "    folder_name (str): name of folder.\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(folder_name) != str:\n",
    "        raise TypeError('expected a string value')\n",
    "\n",
    "    files = glob.glob('./{}/*'.format(folder_name))\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV_GrundlagendesTourismus.pdf is in progress ...\n",
      "IV_GrundlagendesTourismus.pdf is in confidence inserting progress ...\n",
      "IV_GrundlagendesTourismus.pdf is in confidence inserting progress ...\n",
      "IV_GrundlagendesTourismus.pdf is in confidence inserting progress ...\n",
      "IV_GrundlagendesTourismus.pdf is in confidence inserting progress ...\n",
      "IV_GrundlagendesTourismus.pdf is finished. \n",
      "\n",
      "The End!\n"
     ]
    }
   ],
   "source": [
    "#Import modules\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "from mtranslate import translate\n",
    "import cv2\n",
    "import re\n",
    "import imutils\n",
    "import shutil\n",
    "from pytesseract import Output\n",
    "import logging\n",
    "\n",
    "# remove previouse log file\n",
    "os.remove('logfile.log')\n",
    "\n",
    "# Create or get the logger\n",
    "logger = logging.getLogger(__name__)  \n",
    "\n",
    "# set log level\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# define file handler and set formatter\n",
    "file_handler = logging.FileHandler('logfile.log')\n",
    "formatter    = logging.Formatter('\\n\\n%(asctime)s : %(levelname)s : %(name)s : %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# add file handler to logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "#pdf splitting to its pages\n",
    "for pdf in glob.glob('./01-PDFs/*.pdf'):\n",
    "    \n",
    "    similar_text_files = []\n",
    "    similar_CF_text_files = []\n",
    "\n",
    "    file_name = pdf[10:-4]\n",
    "\n",
    "    #delete previous contents of '02-input' folder\n",
    "    #removing_files('02-input')\n",
    "\n",
    "    print('{}.pdf is in progress ...'.format(file_name))\n",
    "\n",
    "    inputpdf = PdfFileReader(open(pdf, \"rb\"))\n",
    "\n",
    "    for ii in range(inputpdf.numPages):\n",
    "        output = PdfFileWriter()\n",
    "        output.addPage(inputpdf.getPage(ii))\n",
    "        if ii < 9:\n",
    "            page_number = f'00{ii+1}'\n",
    "        elif ii < 99:\n",
    "            page_number = f'0{ii+1}'\n",
    "        else:\n",
    "            page_number = f'{ii+1}'\n",
    "        with open(\"./02-input/{}_page-{}.pdf\".format(file_name, page_number), \"wb\") as outputStream:\n",
    "            output.write(outputStream)\n",
    "\n",
    "    #convert pdf(s) to image(s)\n",
    "    for pdf in glob.glob('./02-input/{}*.pdf'.format(file_name)):\n",
    "        pdf_name = pdf[:-4]\n",
    "        cmd = 'magick convert  -density 300   -quality 100  -flatten   \"{}\".pdf  \"{}\".jpg'.format(pdf_name, pdf_name)\n",
    "        os.system(cmd)\n",
    "\n",
    "    # convert image file(s) to text file(s) (in German language)  \n",
    "    for img in glob.glob('./02-input/{}*.jpg'.format(file_name)):\n",
    "            \n",
    "        try:\n",
    "\n",
    "            t1_I2T = time.time()\n",
    "            # create a new folder as name 'file_name'\n",
    "            new_folder = f\"./03-TXTs/{file_name}\" \n",
    "            if not os.path.exists(new_folder):\n",
    "                os.makedirs(new_folder)\n",
    "\n",
    "            #try:\n",
    "\n",
    "            #delete previous contents of '03-TXTs' folder\n",
    "            #removing_files('03-TXTs')\n",
    "\n",
    "            # reading image by opencv\n",
    "            #im_bgr = cv2.imread(img, 0)\n",
    "            #image = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # detecting image orientation and fix that\n",
    "            osd = pytesseract.image_to_osd(Image.open(img))\n",
    "            image_angle = float(re.search('(?<=Rotate: )\\d+', osd).group(0))\n",
    "\n",
    "            #print(\"image_angle = \"+str(image_angle))\n",
    "\n",
    "            if image_angle != 0 :\n",
    "                    cv_image = cv2.imread(img)\n",
    "                    rotated = imutils.rotate_bound(cv_image, image_angle)\n",
    "                    cv2.imwrite(img, rotated)\n",
    "\n",
    "\n",
    "            # applying median blur on the image\n",
    "            kernel_size = 3\n",
    "            image = cv2.imread(img, 0)\n",
    "            m_img = cv2.medianBlur(image,kernel_size)\n",
    "            #m_img = cv2.Laplacian(m_img, cv2.CV_8U)\n",
    "            cv2.imwrite(img, m_img)\n",
    "\n",
    "            # image to text\n",
    "            # 1. by pytesseract\n",
    "            custom_config = r'-c preserve_interword_spaces=1 --psm 6 -l deu'\n",
    "            extractedInformation = pytesseract.image_to_string(Image.open(img), config=custom_config)\n",
    "            with open('./03-TXTs/{}.txt'.format(img[11:-4]), 'w', encoding=\"utf-8\") as file:\n",
    "                file.write(extractedInformation)\n",
    "\n",
    "            similar_text_files.append('./03-TXTs/{}.txt'.format(img[11:-4]))\n",
    "\n",
    "\n",
    "            # 2. by tesseract CLI\n",
    "            #cmd = 'tesseract 103000003673_page-1.jpg tt.txt -c preserve_interword_spaces=1 --psm 4 -l deu'\n",
    "            #os.system(cmd)\n",
    "\n",
    "            # writing with confidence\n",
    "            #print('{}.pdf is in confidence inserting progress ...'.format(file_name))\n",
    "            # 1. creating text data tabel\n",
    "            text_table = pytesseract.image_to_data(Image.open(img), lang='deu', output_type=Output.DATAFRAME)\n",
    "            text_table.to_csv('./03-TXTs/{}/{}.csv'.format(file_name, img[11:-4]), encoding='utf8', index=False)\n",
    "\n",
    "            # 2. creating properties file\n",
    "            Words = len(text_table[text_table.conf>=0]['conf'].index)\n",
    "            Std = text_table[text_table.conf>=0]['conf'].std()\n",
    "            Average = text_table[text_table.conf>=0]['conf'].mean()\n",
    "            Max = text_table[text_table.conf>=0]['conf'].max()\n",
    "            Min = text_table[text_table.conf>=0]['conf'].min()\n",
    "\n",
    "            with open('./03-TXTs/{}/{}_Properties.txt'.format(file_name, img[11:-4]), 'w') as Prop_file:\n",
    "                line1 = 'In the name of GOD\\n'\n",
    "                line2 = f\"Number of detected words = {Words}\"\n",
    "                line3 = f'Standard deviation of confidence = {Std}'\n",
    "                line4 = f'Average confidence = {Average}'\n",
    "                line5 = f'Maximum confidence = {Max}'\n",
    "                line6 = f'Minimum confidence = {Min}'\n",
    "                Prop_file.write(f'{line1}\\n{line2}\\n{line3}\\n{line4}\\n{line5}\\n{line6}\\n\\n\\n')\n",
    "\n",
    "            # 3. converting text file to list\n",
    "            text_list = []\n",
    "            with open('./03-TXTs/{}.txt'.format(img[11:-4]), 'r', encoding='utf8') as file: \n",
    "                # reading each line     \n",
    "                for line in file:\n",
    "                    word = line.split(' ')\n",
    "                    text_list.append(word)\n",
    "\n",
    "            # 4. inserting confidence of each word\n",
    "            start_point = 0\n",
    "            for row in text_list:\n",
    "                for i in range(len(row)):\n",
    "                    word = row[i]\n",
    "                    s_word = word.replace('\\n','')\n",
    "\n",
    "                    # to avoid engaging confidence of iterated words\n",
    "                    for j in range(start_point, text_table.index.stop):\n",
    "                        if text_table.text[j] == s_word:\n",
    "                            confidence = text_table.conf[j]\n",
    "                            row[i] = s_word + f\"({confidence}%)\"\n",
    "                            #start_point = j+1\n",
    "                            break\n",
    "\n",
    "            # 5. creating new text file\n",
    "            new_text_list = []\n",
    "\n",
    "            for k in range(len(text_list)):\n",
    "                words = \" \".join(text_list[k])\n",
    "                new_text_list.append(words)\n",
    "\n",
    "            with open('./03-TXTs/{}_CF.txt'.format(img[11:-4]), 'w', encoding=\"utf-8\") as output_with_confidence_file:\n",
    "                for item in new_text_list:\n",
    "                    output_with_confidence_file.write(\"%s\\n\" % item)\n",
    "\n",
    "            similar_CF_text_files.append('./03-TXTs/{}_CF.txt'.format(img[11:-4]))\n",
    "\n",
    "            # Time consuming\n",
    "            t2_I2T = time.time()\n",
    "            with open('./03-TXTs/{}/{}_Properties.txt'.format(file_name, img[11:-4]), 'a') as Prop_file:\n",
    "\n",
    "                Prop_file.write(\"** Time consuming (image2text and quality estimating) = {} seconds **\"\n",
    "                                .format(str(t2_I2T - t1_I2T)))\n",
    "                \n",
    "                \n",
    "        except:\n",
    "        \n",
    "            logger.exception(f\"When \\\"{img}\\\" was being processed an error has occured!\")\n",
    "\n",
    "    # merge text files             \n",
    "\n",
    "    with open(f\"./03-TXTs/{file_name}/{file_name}.txt\",'wb') as outfile:\n",
    "        for f in similar_text_files:\n",
    "            with open(f,'rb') as infile:\n",
    "                outfile.write(b\"\\n\\n********** The Beginning of The Page **********\\n\\n\")\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "\n",
    "\n",
    "    # merge CF text files             \n",
    "\n",
    "    with open(f\"./03-TXTs/{file_name}/{file_name}_CF.txt\",'wb') as outfile:\n",
    "        for f in similar_CF_text_files:\n",
    "            with open(f,'rb') as infile:\n",
    "                outfile.write(b\"\\n\\n********** The Beginning of The Page **********\\n\\n\")\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # copy the processed pdf to its processing folder\n",
    "    shutil.copyfile(f\"./01-PDFs/{file_name}.pdf\", f\"./03-TXTs/{file_name}/{file_name}.pdf\")\n",
    "\n",
    "    # remove seperated pages of the pdf file\n",
    "    files = glob.glob('./03-TXTs/*.txt')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    # translating to English\n",
    "            \n",
    "    #txt = f\"./03-TXTs/{file_name}.txt\"\n",
    "\n",
    "    #with open(txt, 'r', encoding=\"utf8\") as file:\n",
    "        #text = file.read()\n",
    "        #trans = translate(text,\"en\",\"de\")\n",
    "        #with open('./04-output/{}_translated.txt'.format(txt[10:-4]), 'w', encoding=\"utf-8\") as file:\n",
    "            #file.write(trans)\n",
    "                \n",
    "    \n",
    "    print('{}.pdf is finished. \\n'.format(file_name))\n",
    "\n",
    "    \n",
    "\n",
    "print('The End!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hocr_to_dataframe(fp):\n",
    "\n",
    "    from lxml import etree\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    doc = etree.parse(fp)\n",
    "    words = []\n",
    "    wordConf = []\n",
    "    X1 = []\n",
    "    Y1 = []\n",
    "    X2 = []\n",
    "    Y2 = []\n",
    "\n",
    "    for path in doc.xpath('//*'):\n",
    "        if 'ocrx_word' in path.values():\n",
    "            conf = [x for x in path.values() if 'x_wconf' in x][0]\n",
    "            wordConf.append(int(conf.split('x_wconf ')[1]))\n",
    "            \n",
    "            bbox = [x for x in path.values() if 'bbox' in x][0]\n",
    "            X1.append(int(bbox.split('bbox ')[1].split(';')[0].split(' ')[0]))\n",
    "            Y1.append(int(bbox.split('bbox ')[1].split(';')[0].split(' ')[1]))\n",
    "            X2.append(int(bbox.split('bbox ')[1].split(';')[0].split(' ')[2]))\n",
    "            Y2.append(int(bbox.split('bbox ')[1].split(';')[0].split(' ')[3]))\n",
    "            \n",
    "            words.append(path.text)\n",
    "\n",
    "    dfReturn = pd.DataFrame({'word' : words,\n",
    "                             'confidence' : wordConf,\n",
    "                             'X1' : X1,\n",
    "                             'Y1' : Y1,\n",
    "                             'X2' : X2,\n",
    "                             'Y2' : Y2})\n",
    "\n",
    "    return(dfReturn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = hocr_to_dataframe('contE.hocr')\n",
    "dataframe.to_excel(\"contE.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
